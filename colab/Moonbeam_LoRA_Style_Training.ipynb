{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moonbeam LoRA Style Training (Colab)\n",
    "Train a LoRA adapter (e.g., Chopin/Liszt/Bach style) from your own MIDI files, then reuse the adapter in `Moonbeam_Quickstart.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Runtime setup\n",
    "Use **GPU runtime** in Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError('Please switch Colab runtime to GPU.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Clone repo and install dependencies (exact README commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_dir = Path('/content/Moonbeam-MIDI-Foundation-Model')\n",
    "if repo_dir.exists():\n",
    "    os.chdir(repo_dir)\n",
    "    os.system('git fetch origin --prune')\n",
    "    if os.system('git reset --hard origin/main') != 0:\n",
    "        os.system('git reset --hard origin/master')\n",
    "else:\n",
    "    os.system('git clone https://github.com/guozixunnicolas/Moonbeam-MIDI-Foundation-Model /content/Moonbeam-MIDI-Foundation-Model')\n",
    "\n",
    "%cd /content/Moonbeam-MIDI-Foundation-Model\n",
    "!pip install .\n",
    "!pip install src/llama_recipes/transformers_minimal/.\n",
    "!pip install huggingface_hub pandas mido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Download pretrained checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "CKPT_FILENAME = 'moonbeam_309M.pt'  #@param ['moonbeam_309M.pt', 'moonbeam_839M.pt']\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id='guozixunnicolas/moonbeam-midi-foundation-model',\n",
    "    filename=CKPT_FILENAME,\n",
    ")\n",
    "print('Checkpoint:', ckpt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Upload style MIDI zip and preprocess to `.npy` + split CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import LlamaConfig\n",
    "from llama_recipes.datasets.music_tokenizer import MusicTokenizer\n",
    "\n",
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "TRAIN_RATIO = 0.9  #@param {type:\"number\"}\n",
    "\n",
    "uploaded = files.upload()\n",
    "if not uploaded:\n",
    "    raise RuntimeError('Please upload a zip containing MIDI files.')\n",
    "zip_name = next(iter(uploaded.keys()))\n",
    "\n",
    "work_dir = Path('/content/style_data') / STYLE_NAME\n",
    "raw_dir = work_dir / 'raw_midis'\n",
    "proc_dir = work_dir / 'processed'\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "proc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'r') as zf:\n",
    "    zf.extractall(raw_dir)\n",
    "\n",
    "midi_files = sorted([p for p in raw_dir.rglob('*') if p.suffix.lower() in {'.mid', '.midi'}])\n",
    "if not midi_files:\n",
    "    raise RuntimeError('No MIDI files found in uploaded zip.')\n",
    "\n",
    "cfg = LlamaConfig.from_pretrained('src/llama_recipes/configs/model_config.json')\n",
    "tokenizer = MusicTokenizer(\n",
    "    timeshift_vocab_size=cfg.onset_vocab_size,\n",
    "    dur_vocab_size=cfg.dur_vocab_size,\n",
    "    octave_vocab_size=cfg.octave_vocab_size,\n",
    "    pitch_class_vocab_size=cfg.pitch_class_vocab_size,\n",
    "    instrument_vocab_size=cfg.instrument_vocab_size,\n",
    "    velocity_vocab_size=cfg.velocity_vocab_size,\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for idx, midi_path in enumerate(midi_files):\n",
    "    try:\n",
    "        tokens = tokenizer.midi_to_compound(str(midi_path))\n",
    "        arr = np.asarray(tokens, dtype=np.int16)\n",
    "        if arr.size == 0:\n",
    "            continue\n",
    "        out_name = f'{STYLE_NAME}_{idx:05d}.npy'\n",
    "        np.save(proc_dir / out_name, arr)\n",
    "        rows.append({'file_base_name': out_name})\n",
    "    except Exception as e:\n",
    "        print(f'[skip] {midi_path.name}: {e}')\n",
    "\n",
    "if len(rows) < 2:\n",
    "    raise RuntimeError('Need at least 2 valid MIDI files after preprocessing.')\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(rows)\n",
    "split_idx = max(1, min(len(rows)-1, int(len(rows) * float(TRAIN_RATIO))))\n",
    "for i, r in enumerate(rows):\n",
    "    r['split'] = 'train' if i < split_idx else 'test'\n",
    "\n",
    "split_csv = work_dir / f'{STYLE_NAME}_split.csv'\n",
    "pd.DataFrame(rows).to_csv(split_csv, index=False)\n",
    "\n",
    "print('Preprocessed files:', len(rows))\n",
    "print('Data dir:', work_dir)\n",
    "print('CSV:', split_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Run LoRA finetuning (unconditional generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "NUM_EPOCHS = 5  #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 1  #@param {type:\"integer\"}\n",
    "LR = 0.0003  #@param {type:\"number\"}\n",
    "CONTEXT_LENGTH = 1024  #@param {type:\"integer\"}\n",
    "\n",
    "from pathlib import Path\n",
    "style_root = Path('/content/style_data') / STYLE_NAME\n",
    "split_csv = style_root / f'{STYLE_NAME}_split.csv'\n",
    "\n",
    "cmd = f'''torchrun --nnodes 1 --nproc_per_node 1 recipes/finetuning/real_finetuning_uncon_gen.py \\\n",
    "  --lr {LR} \\\n",
    "  --val_batch_size 1 \\\n",
    "  --run_validation True \\\n",
    "  --validation_interval 20 \\\n",
    "  --save_metrics True \\\n",
    "  --dist_checkpoint_root_folder checkpoints/finetuned_checkpoints/{STYLE_NAME}_lora \\\n",
    "  --dist_checkpoint_folder ddp \\\n",
    "  --trained_checkpoint_path {ckpt_path} \\\n",
    "  --pure_bf16 True \\\n",
    "  --enable_ddp True \\\n",
    "  --use_peft True \\\n",
    "  --peft_method lora \\\n",
    "  --quantization False \\\n",
    "  --model_name moonbeam_{STYLE_NAME} \\\n",
    "  --dataset lakhmidi_dataset \\\n",
    "  --data_dir {style_root} \\\n",
    "  --csv_file {split_csv} \\\n",
    "  --output_dir checkpoints/finetuned_checkpoints/{STYLE_NAME}_lora \\\n",
    "  --batch_size_training {BATCH_SIZE} \\\n",
    "  --context_length {CONTEXT_LENGTH} \\\n",
    "  --num_epochs {NUM_EPOCHS} \\\n",
    "  --use_wandb False \\\n",
    "  --gamma 0.99'''\n",
    "print(cmd)\n",
    "!{cmd}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Zip LoRA adapter for upload into quickstart notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "adapter_root = Path('checkpoints/finetuned_checkpoints') / f'{STYLE_NAME}_lora'\n",
    "\n",
    "candidate_dirs = [d for d in [adapter_root, *adapter_root.rglob('*')] if d.is_dir() and (d / 'adapter_config.json').exists()]\n",
    "if not candidate_dirs:\n",
    "    raise RuntimeError('No adapter_config.json found. Check training output folder.')\n",
    "\n",
    "adapter_dir = candidate_dirs[0]\n",
    "zip_path = Path('/content') / f'{STYLE_NAME}_lora_adapter.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    for file_path in adapter_dir.rglob('*'):\n",
    "        if file_path.is_file():\n",
    "            zf.write(file_path, file_path.relative_to(adapter_dir.parent))\n",
    "\n",
    "print('Adapter zip:', zip_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}