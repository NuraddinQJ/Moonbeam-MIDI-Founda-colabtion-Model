{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moonbeam LoRA Style Training (Colab)\n",
    "Train a style LoRA (e.g., Chopin/Liszt/Bach) from uploaded MIDI files, then export a zip for `Moonbeam_Quickstart.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Runtime setup\n",
    "Use **GPU** runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError('Please switch Colab runtime to GPU.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Clone repo and install dependencies (exact README commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_dir = Path('/content/Moonbeam-MIDI-Foundation-Model')\n",
    "if repo_dir.exists():\n",
    "    os.chdir(repo_dir)\n",
    "    os.system('git fetch origin --prune')\n",
    "    if os.system('git reset --hard origin/main') != 0:\n",
    "        os.system('git reset --hard origin/master')\n",
    "else:\n",
    "    os.system('git clone https://github.com/guozixunnicolas/Moonbeam-MIDI-Foundation-Model /content/Moonbeam-MIDI-Foundation-Model')\n",
    "\n",
    "%cd /content/Moonbeam-MIDI-Foundation-Model\n",
    "!pip install .\n",
    "!pip install src/llama_recipes/transformers_minimal/.\n",
    "!pip install huggingface_hub pandas mido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Download pretrained checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "CKPT_FILENAME = 'moonbeam_309M.pt'  #@param ['moonbeam_309M.pt', 'moonbeam_839M.pt']\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id='guozixunnicolas/moonbeam-midi-foundation-model',\n",
    "    filename=CKPT_FILENAME,\n",
    ")\n",
    "print('Checkpoint:', ckpt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Upload style MIDI zip and preprocess (absolute /content paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import LlamaConfig\n",
    "from llama_recipes.datasets.music_tokenizer import MusicTokenizer\n",
    "\n",
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "TRAIN_RATIO = 0.9  #@param {type:\"number\"}\n",
    "\n",
    "BASE_DATA_DIR = Path('/content/processed_datasets/unconditional')\n",
    "STYLE_DATA_DIR = BASE_DATA_DIR / STYLE_NAME\n",
    "RAW_DIR = STYLE_DATA_DIR / 'raw_midis'\n",
    "PROCESSED_DIR = STYLE_DATA_DIR / 'processed'\n",
    "TRAIN_JSON_DIR = STYLE_DATA_DIR / 'train'\n",
    "TEST_JSON_DIR = STYLE_DATA_DIR / 'test'\n",
    "SPLIT_CSV = STYLE_DATA_DIR / f'{STYLE_NAME}_split.csv'\n",
    "\n",
    "for d in [RAW_DIR, PROCESSED_DIR, TRAIN_JSON_DIR, TEST_JSON_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "uploaded = files.upload()\n",
    "if not uploaded:\n",
    "    raise RuntimeError('Please upload a zip containing MIDI files.')\n",
    "zip_name = next(iter(uploaded.keys()))\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'r') as zf:\n",
    "    zf.extractall(RAW_DIR)\n",
    "\n",
    "midi_files = sorted([p for p in RAW_DIR.rglob('*') if p.suffix.lower() in {'.mid', '.midi'}])\n",
    "if not midi_files:\n",
    "    raise RuntimeError('No MIDI files found in uploaded zip.')\n",
    "\n",
    "cfg = LlamaConfig.from_pretrained('/content/Moonbeam-MIDI-Foundation-Model/src/llama_recipes/configs/model_config.json')\n",
    "tokenizer = MusicTokenizer(\n",
    "    timeshift_vocab_size=cfg.onset_vocab_size,\n",
    "    dur_vocab_size=cfg.dur_vocab_size,\n",
    "    octave_vocab_size=cfg.octave_vocab_size,\n",
    "    pitch_class_vocab_size=cfg.pitch_class_vocab_size,\n",
    "    instrument_vocab_size=cfg.instrument_vocab_size,\n",
    "    velocity_vocab_size=cfg.velocity_vocab_size,\n",
    ")\n",
    "\n",
    "rows = []\n",
    "valid = 0\n",
    "for idx, midi_path in enumerate(midi_files):\n",
    "    try:\n",
    "        tokens = tokenizer.midi_to_compound(str(midi_path))\n",
    "        arr = np.asarray(tokens, dtype=np.int16)\n",
    "        if arr.size == 0:\n",
    "            continue\n",
    "        out_name = f'{STYLE_NAME}_{idx:05d}.npy'\n",
    "        np.save(PROCESSED_DIR / out_name, arr)\n",
    "        rows.append({'file_base_name': out_name, 'token_length': int(len(tokens))})\n",
    "        valid += 1\n",
    "    except Exception as e:\n",
    "        print(f'[skip] {midi_path.name}: {e}')\n",
    "\n",
    "if len(rows) < 2:\n",
    "    raise RuntimeError('Need at least 2 valid MIDI files after preprocessing.')\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(rows)\n",
    "split_idx = max(1, min(len(rows)-1, int(len(rows) * float(TRAIN_RATIO))))\n",
    "for i, r in enumerate(rows):\n",
    "    r['split'] = 'train' if i < split_idx else 'test'\n",
    "\n",
    "pd.DataFrame([{'file_base_name': r['file_base_name'], 'split': r['split']} for r in rows]).to_csv(SPLIT_CSV, index=False)\n",
    "\n",
    "for r in rows:\n",
    "    target_dir = TRAIN_JSON_DIR if r['split'] == 'train' else TEST_JSON_DIR\n",
    "    meta = {\n",
    "        'file_base_name': r['file_base_name'],\n",
    "        'token_length': r['token_length'],\n",
    "        'split': r['split'],\n",
    "    }\n",
    "    (target_dir / f\"{Path(r['file_base_name']).stem}.json\").write_text(json.dumps(meta))\n",
    "\n",
    "print('Valid preprocessed files:', valid)\n",
    "print('Processed dataset dir:', STYLE_DATA_DIR.resolve())\n",
    "print('Split CSV:', SPLIT_CSV.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b) Dataset token-length analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "train_json_dir = Path(f'/content/processed_datasets/unconditional/{STYLE_NAME}/train')\n",
    "\n",
    "if not train_json_dir.exists():\n",
    "    print(f'[info] Dataset folder missing: {train_json_dir}')\n",
    "else:\n",
    "    json_files = sorted(train_json_dir.glob('*.json'))\n",
    "    if not json_files:\n",
    "        print(f'[info] No JSON files found under: {train_json_dir}')\n",
    "    else:\n",
    "        lengths = []\n",
    "        for p in json_files:\n",
    "            try:\n",
    "                d = json.loads(p.read_text())\n",
    "                tl = d.get('token_length')\n",
    "                if tl is None and isinstance(d.get('tokens'), list):\n",
    "                    tl = len(d['tokens'])\n",
    "                if tl is not None:\n",
    "                    lengths.append(int(tl))\n",
    "            except Exception as e:\n",
    "                print(f'[skip] {p.name}: {e}')\n",
    "\n",
    "        if not lengths:\n",
    "            print('[info] No valid token lengths found in JSON files.')\n",
    "        else:\n",
    "            arr = np.array(lengths)\n",
    "            p50, p75, p90, p95 = np.percentile(arr, [50, 75, 90, 95])\n",
    "            print(f'total files: {len(arr)}')\n",
    "            print(f'min/max/avg: {arr.min()} / {arr.max()} / {arr.mean():.2f}')\n",
    "            print(f'p50/p75/p90/p95: {p50:.1f} / {p75:.1f} / {p90:.1f} / {p95:.1f}')\n",
    "\n",
    "            if p95 < 1000:\n",
    "                rec = 1024\n",
    "            elif p95 < 2000:\n",
    "                rec = 2048\n",
    "            else:\n",
    "                rec = 4096\n",
    "            print(f'Recommended context_length: {rec}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Run LoRA finetuning (with sanity checks, absolute paths, and clear status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "NUM_EPOCHS = 5  #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 1  #@param {type:\"integer\"}\n",
    "LR = 0.0003  #@param {type:\"number\"}\n",
    "CONTEXT_LENGTH = 1024  #@param {type:\"integer\"}\n",
    "\n",
    "style_root = Path(f'/content/processed_datasets/unconditional/{STYLE_NAME}')\n",
    "split_csv = style_root / f'{STYLE_NAME}_split.csv'\n",
    "out_dir = Path(f'/content/checkpoints/finetuned_checkpoints/{STYLE_NAME}_lora')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not style_root.exists():\n",
    "    raise FileNotFoundError(f'Missing dataset dir: {style_root}')\n",
    "if not (style_root / 'processed').exists():\n",
    "    raise FileNotFoundError(f\"Missing processed dir: {style_root / 'processed'}\")\n",
    "if not split_csv.exists():\n",
    "    raise FileNotFoundError(f'Missing split CSV: {split_csv}')\n",
    "\n",
    "args = [\n",
    "    'torchrun', '--nnodes', '1', '--nproc_per_node', '1',\n",
    "    '/content/Moonbeam-MIDI-Foundation-Model/recipes/finetuning/real_finetuning_uncon_gen.py',\n",
    "    '--lr', str(LR),\n",
    "    '--val_batch_size', '1',\n",
    "    '--run_validation', 'True',\n",
    "    '--validation_interval', '20',\n",
    "    '--save_metrics', 'True',\n",
    "    '--dist_checkpoint_root_folder', '/content/checkpoints/finetuned_checkpoints',\n",
    "    '--dist_checkpoint_folder', f'{STYLE_NAME}_lora_ddp',\n",
    "    '--trained_checkpoint_path', str(ckpt_path),\n",
    "    '--ddp_config.pure_bf16', 'True',\n",
    "    '--enable_ddp', 'True',\n",
    "    '--use_peft', 'True',\n",
    "    '--peft_method', 'lora',\n",
    "    '--quantization', 'False',\n",
    "    '--model_name', f'moonbeam_{STYLE_NAME}',\n",
    "    '--dataset', 'lakhmidi_dataset',\n",
    "    '--lakhmidi_dataset.data_dir', str(style_root),\n",
    "    '--lakhmidi_dataset.csv_file', str(split_csv),\n",
    "    '--output_dir', str(out_dir),\n",
    "    '--batch_size_training', str(BATCH_SIZE),\n",
    "    '--context_length', str(CONTEXT_LENGTH),\n",
    "    '--num_epochs', str(NUM_EPOCHS),\n",
    "    '--use_wandb', 'False',\n",
    "    '--gamma', '0.99',\n",
    "]\n",
    "\n",
    "print('Launching training command:\\n' + ' '.join(args))\n",
    "run = subprocess.run(args, capture_output=True, text=True)\n",
    "print(run.stdout)\n",
    "if run.stderr:\n",
    "    print('--- STDERR ---')\n",
    "    print(run.stderr)\n",
    "\n",
    "combined = (run.stdout or '') + '\\n' + (run.stderr or '')\n",
    "unknown_hits = [line for line in combined.splitlines() if 'Warning: unknown parameter' in line]\n",
    "if unknown_hits:\n",
    "    raise RuntimeError('Unknown parameter warnings found:\\n' + '\\n'.join(unknown_hits))\n",
    "\n",
    "if run.returncode != 0:\n",
    "    raise RuntimeError(f'Training failed with return code {run.returncode}')\n",
    "\n",
    "print('Training finished successfully.')\n",
    "print('Output dir:', out_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Package best LoRA adapter + print final training summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "STYLE_NAME = 'chopin'  #@param {type:\"string\"}\n",
    "out_dir = Path(f'/content/checkpoints/finetuned_checkpoints/{STYLE_NAME}_lora')\n",
    "metrics_files = sorted(out_dir.glob('metrics_data_*.json'), key=lambda p: p.stat().st_mtime)\n",
    "metrics_path = metrics_files[-1] if metrics_files else None\n",
    "adapter_dirs = [d for d in [out_dir, *out_dir.rglob('*')] if d.is_dir() and (d / 'adapter_config.json').exists()]\n",
    "if not adapter_dirs:\n",
    "    raise RuntimeError(f'No adapter folders with adapter_config.json found in {out_dir}')\n",
    "def parse_folder_key(p: Path):\n",
    "    stem = p.name.replace('.safetensors','')\n",
    "    try:\n",
    "        ep, st = stem.split('-', 1)\n",
    "        return (int(ep), int(st))\n",
    "    except Exception:\n",
    "        return (-1, -1)\n",
    "adapter_dirs_sorted = sorted(adapter_dirs, key=lambda p: (parse_folder_key(p), p.stat().st_mtime))\n",
    "selected = None\n",
    "select_reason = ''\n",
    "best_eval = None\n",
    "last_completed_epoch = None\n",
    "if metrics_path:\n",
    "    metrics = json.loads(metrics_path.read_text())\n",
    "    val_losses = [float(x) for x in metrics.get('val_step_loss', []) if x is not None]\n",
    "    train_epoch_losses = metrics.get('train_epoch_loss', [])\n",
    "    if train_epoch_losses:\n",
    "        last_completed_epoch = len(train_epoch_losses)\n",
    "    if val_losses:\n",
    "        best_i = min(range(len(val_losses)), key=lambda i: val_losses[i])\n",
    "        best_eval = val_losses[best_i]\n",
    "        if best_i < len(adapter_dirs_sorted):\n",
    "            selected = adapter_dirs_sorted[best_i]\n",
    "            select_reason = f'best eval loss from metrics index {best_i} (loss={best_eval:.6f})'\n",
    "if selected is None:\n",
    "    selected = max(adapter_dirs, key=lambda p: p.stat().st_mtime)\n",
    "    select_reason = 'most recent adapter folder (metrics missing or insufficient)'\n",
    "required_files = ['adapter_model.safetensors', 'adapter_config.json']\n",
    "for rf in required_files:\n",
    "    if not (selected / rf).exists():\n",
    "        raise RuntimeError(f'Selected adapter folder missing required file: {selected/rf}')\n",
    "ts = datetime.now().strftime('%Y%m%d_%H-%M')\n",
    "zip_path = Path('/content') / f'{STYLE_NAME}_{ts}_lora_adapter.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    for name in required_files:\n",
    "        zf.write(selected / name, arcname=name)\n",
    "    readme = selected / 'README.md'\n",
    "    if readme.exists():\n",
    "        zf.write(readme, arcname='README.md')\n",
    "if last_completed_epoch is None:\n",
    "    last_completed_epoch = parse_folder_key(max(adapter_dirs_sorted, key=lambda p: parse_folder_key(p)))[0]\n",
    "print('=== Training Summary ===')\n",
    "print('Selected adapter folder:', selected.resolve())\n",
    "print('Selection reason:', select_reason)\n",
    "print('Last completed epoch:', last_completed_epoch)\n",
    "print('Best eval loss:', best_eval if best_eval is not None else 'N/A')\n",
    "print('Metrics JSON path:', str(metrics_path.resolve()) if metrics_path else 'N/A (metrics file not found)')\n",
    "print('Adapter zip path:', zip_path.resolve())\n",
    "# Stopping reason heuristic\n",
    "if metrics_path and best_eval is not None:\n",
    "    print('Detected stop reason: normal completion (metrics/checkpoints present).')\n",
    "else:\n",
    "    print('Detected stop reason: unknown/partial run (check runtime logs for interruption).')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
